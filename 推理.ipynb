{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inferencer.inferencer import Inferencer\n",
    "from retriever.retriever_cone import ConeRetriever\n",
    "from retriever.retriever_topk import TopkRetriever\n",
    "from datareader.datareader import DatasetReader\n",
    "\n",
    "\n",
    "obj = Inferencer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.generate_direct_prompt('/data/lhb/test-openicl-0.1.8/EHR_Base/results/readmission_prediction/randseed36/top3/qwen/top3_ice_idx.json', \n",
    "                           'top3_prompt_deepseek_r1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inferencer.generete_deepseek_r1_prompt() missing 2 required positional arguments: 'input_path' and 'output_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerete_deepseek_r1_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Inferencer.generete_deepseek_r1_prompt() missing 2 required positional arguments: 'input_path' and 'output_path'"
     ]
    }
   ],
   "source": [
    "obj.generete_deepseek_r1_prompt('/data/lhb/test-openicl-0.1.8/EHR_Base/results/readmission_prediction/randseed36/top3/bge/top3_prompt_deepseek_r1.json',\n",
    "                                'top3_prompt_deepseek_r1_with_response.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:59,  5.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [17:07,  5.14s/it]\n"
     ]
    }
   ],
   "source": [
    "obj.inference('/data/lhb/test-openicl-0.1.8/EHR_Base/results/readmission_prediction/randseed36/top3/bge/top3_prompt_direct.json',\n",
    "              'top3_res_direct.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top3 retrive is going...: 100%|██████████| 200/200 [00:34<00:00,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from inferencer.inferencer import Inferencer\n",
    "from retriever.retriever_cone import ConeRetriever\n",
    "from retriever.retriever_topk import TopkRetriever\n",
    "from datareader.datareader import DatasetReader\n",
    "\n",
    "obj = TopkRetriever()\n",
    "\n",
    "res = obj.topk_retrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([39671, 25726, 6542], 200)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0], len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('top3_ice_idx.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(res, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd394b9db5c447a880562e0014ced792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from inferencer.inferencer import Inferencer\n",
    "from retriever.retriever_cone import ConeRetriever\n",
    "from retriever.retriever_topk import TopkRetriever\n",
    "from datareader.datareader import DatasetReader\n",
    "\n",
    "obj = ConeRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = obj.cone_retrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openicl0.1.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
